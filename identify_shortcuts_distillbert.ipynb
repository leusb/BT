{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e9dc470",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leosteiner/Desktop/BT/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dec6a7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./distillbert-base-finetuned\"\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2394abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = load_dataset('imdb')\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6a6e737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['I love sci-fi and am willing to put up with a lot. Sci-fi movies/TV are usually underfunded, under-appreciated and misunderstood. I tried to like this, I really did, but it is to good TV sci-fi as Babylon 5 is to Star Trek (the original). Silly prosthetics, cheap cardboard sets, stilted dialogues, CG that doesn\\'t match the background, and painfully one-dimensional characters cannot be overcome with a \\'sci-fi\\' setting. (I\\'m sure there are those of you out there who think Babylon 5 is good sci-fi TV. It\\'s not. It\\'s clichéd and uninspiring.) While US viewers might like emotion and character development, sci-fi is a genre that does not take itself seriously (cf. Star Trek). It may treat important issues, yet not as a serious philosophy. It\\'s really difficult to care about the characters here as they are not simply foolish, just missing a spark of life. Their actions and reactions are wooden and predictable, often painful to watch. The makers of Earth KNOW it\\'s rubbish as they have to always say \"Gene Roddenberry\\'s Earth...\" otherwise people would not continue watching. Roddenberry\\'s ashes must be turning in their orbit as this dull, cheap, poorly edited (watching it without advert breaks really brings this home) trudging Trabant of a show lumbers into space. Spoiler. So, kill off a main character. And then bring him back as another actor. Jeeez! Dallas all over again.'],\n",
       " 'label': [0]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99c11c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Eval Single Phrase\n",
    "\n",
    "import re\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate_phrase_subset(model,\n",
    "                           tokenizer,\n",
    "                           dataset_split,\n",
    "                           phrase,\n",
    "                           batch_size=16,\n",
    "                           max_length=512,\n",
    "                           text_key=\"text\",\n",
    "                           label_key=\"label\",\n",
    "                           use_regex=False):\n",
    "    \"\"\"\n",
    "    Evaluate model accuracy and label distributions on subset of examples\n",
    "    containing a given phrase or regex pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1) Filter examples and create subset\n",
    "    if use_regex:\n",
    "        regex = re.compile(phrase, flags=re.IGNORECASE) # compile for efficiency\n",
    "\n",
    "        def contains(example):\n",
    "            return bool(regex.search(example[text_key]))\n",
    "    else:\n",
    "        phrase_lower = phrase.lower()\n",
    "\n",
    "        def contains(example):\n",
    "            return phrase_lower in example[text_key].lower()\n",
    "\n",
    "    subset = dataset_split.filter(contains)\n",
    "    num_examples = len(subset) # Count occurances\n",
    "\n",
    "    if num_examples == 0:\n",
    "        print(f\"No examples found for phrase '{phrase}'\")\n",
    "        return None\n",
    "\n",
    "    # 2) Tokenize\n",
    "    def tokenize_fn(batch):\n",
    "        return tokenizer(\n",
    "            batch[text_key],\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        )\n",
    "\n",
    "    tokenized_dataset = subset.map(tokenize_fn, batched=True)\n",
    "    tokenized_dataset.set_format(\n",
    "        type=\"torch\",\n",
    "        columns=[\"input_ids\", \"attention_mask\", label_key]\n",
    "    )\n",
    "\n",
    "    dataloader = DataLoader(tokenized_dataset, batch_size=batch_size)\n",
    "\n",
    "    # 3) Device setup\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    elif torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    # 4) Evaluate\n",
    "    correct = total = 0\n",
    "    gold_counts, pred_counts = Counter(), Counter()\n",
    "\n",
    "    with torch.no_grad(): #\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[label_key].to(device)\n",
    "\n",
    "            # run model\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "\n",
    "            correct += (preds == labels).sum().item()# num of correct rpredictions\n",
    "            total += labels.size(0) # num of samples in the batch\n",
    "\n",
    "            gold_counts.update(labels.cpu().tolist())\n",
    "            pred_counts.update(preds.cpu().tolist())\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "    print(f\"Phrase/Pattern: '{phrase}' (regex={use_regex})\")\n",
    "    print(f\"Number of examples: {total}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Gold label distribution (0=neg, 1=pos): {gold_counts}\")\n",
    "    print(f\"Pred label distribution (0=neg, 1=pos): {pred_counts}\")\n",
    "\n",
    "    return {\n",
    "        \"phrase\": phrase,\n",
    "        \"regex_used\": use_regex,\n",
    "        \"num_examples\": total,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"gold_label_distribution\": dict(gold_counts),\n",
    "        \"pred_label_distribution\": dict(pred_counts),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acb4e0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase/Pattern: 'spielberg' (regex=False)\n",
      "Number of examples: 101\n",
      "Accuracy: 0.9901\n",
      "Gold label distribution (0=neg, 1=pos): Counter({1: 60, 0: 41})\n",
      "Pred label distribution (0=neg, 1=pos): Counter({1: 61, 0: 40})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'phrase': 'spielberg',\n",
       " 'regex_used': False,\n",
       " 'num_examples': 101,\n",
       " 'accuracy': 0.9900990099009901,\n",
       " 'gold_label_distribution': {0: 41, 1: 60},\n",
       " 'pred_label_distribution': {0: 40, 1: 61}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_phrase_subset(model, tokenizer, dataset[\"train\"],\n",
    "                       phrase=\"spielberg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21c15abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distinct words in positive reviews: 71502\n",
      "Distinct words in negative reviews: 70189\n",
      "Example: {'spielberg': (48, 30), 'tarantino': (21, 35), 'excellent': (1425, 350), 'terrible': (215, 1114)}\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Counters: in how many REVIEWS each word appears (pos/neg)\n",
    "c_pos_word = Counter()\n",
    "c_neg_word = Counter()\n",
    "\n",
    "# Simple word pattern:\n",
    "# - sequences of letters, possibly with ' or - inside (e.g. \"spielberg's\", \"well-made\")\n",
    "word_re = re.compile(r\"[A-Za-z][A-Za-z'-]*\")\n",
    "# TODO Extract digits/ ratings and exclamation marks maybe?\n",
    "\n",
    "for example in train_data: # For now inspecting training data\n",
    "    text = example[\"text\"].lower()\n",
    "    label = example[\"label\"]  # 1 = pos, 0 = neg\n",
    "\n",
    "    # Extract words\n",
    "    words = word_re.findall(text)\n",
    "\n",
    "    # Use unique words per sample\n",
    "    unique_words = set(words)\n",
    "\n",
    "    if label == 1:\n",
    "        for word in unique_words:\n",
    "            c_pos_word[word] += 1\n",
    "    else:\n",
    "        for word in unique_words:\n",
    "            c_neg_word[word] += 1\n",
    "\n",
    "print(\"Distinct words in positive reviews:\", len(c_pos_word))\n",
    "print(\"Distinct words in negative reviews:\", len(c_neg_word))\n",
    "# sanity check\n",
    "print(\"Example:\", {w: (c_pos_word[w], c_neg_word[w]) for w in [\"spielberg\", \"tarantino\", \"excellent\", \"terrible\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e161f9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top positive-associated words:\n",
      "excellently          bias=0.967, total=60, pos=58, neg=2\n",
      "first-rate           bias=0.943, total=53, pos=50, neg=3\n",
      "delightfully         bias=0.940, total=50, pos=47, neg=3\n",
      "flawless             bias=0.934, total=122, pos=114, neg=8\n",
      "matthau              bias=0.923, total=65, pos=60, neg=5\n",
      "superbly             bias=0.915, total=117, pos=107, neg=10\n",
      "perfection           bias=0.903, total=134, pos=121, neg=13\n",
      "heartbreaking        bias=0.889, total=72, pos=64, neg=8\n",
      "captures             bias=0.887, total=203, pos=180, neg=23\n",
      "wonderfully          bias=0.884, total=311, pos=275, neg=36\n",
      "explores             bias=0.882, total=68, pos=60, neg=8\n",
      "hawke                bias=0.882, total=51, pos=45, neg=6\n",
      "expertly             bias=0.881, total=59, pos=52, neg=7\n",
      "masterful            bias=0.881, total=84, pos=74, neg=10\n",
      "refreshing           bias=0.873, total=197, pos=172, neg=25\n",
      "breathtaking         bias=0.871, total=163, pos=142, neg=21\n",
      "must-see             bias=0.871, total=124, pos=108, neg=16\n",
      "deliciously          bias=0.868, total=53, pos=46, neg=7\n",
      "voight               bias=0.864, total=66, pos=57, neg=9\n",
      "affection            bias=0.863, total=73, pos=63, neg=10\n",
      "peters               bias=0.863, total=51, pos=44, neg=7\n",
      "delightful           bias=0.861, total=252, pos=217, neg=35\n",
      "victoria             bias=0.861, total=72, pos=62, neg=10\n",
      "powell               bias=0.856, total=97, pos=83, neg=14\n",
      "underrated           bias=0.854, total=226, pos=193, neg=33\n",
      "beautifully          bias=0.853, total=408, pos=348, neg=60\n",
      "top-notch            bias=0.853, total=68, pos=58, neg=10\n",
      "gripping             bias=0.852, total=142, pos=121, neg=21\n",
      "delight              bias=0.849, total=152, pos=129, neg=23\n",
      "sadness              bias=0.847, total=111, pos=94, neg=17\n",
      "timeless             bias=0.846, total=117, pos=99, neg=18\n",
      "heartwarming         bias=0.844, total=64, pos=54, neg=10\n",
      "walsh                bias=0.843, total=51, pos=43, neg=8\n",
      "superb               bias=0.843, total=616, pos=519, neg=97\n",
      "delicate             bias=0.841, total=63, pos=53, neg=10\n",
      "mann                 bias=0.840, total=50, pos=42, neg=8\n",
      "understated          bias=0.839, total=87, pos=73, neg=14\n",
      "mesmerizing          bias=0.839, total=62, pos=52, neg=10\n",
      "favorites            bias=0.838, total=179, pos=150, neg=29\n",
      "touching             bias=0.838, total=413, pos=346, neg=67\n",
      "unforgettable        bias=0.837, total=141, pos=118, neg=23\n",
      "extraordinary        bias=0.833, total=162, pos=135, neg=27\n",
      "absorbing            bias=0.833, total=54, pos=45, neg=9\n",
      "winters              bias=0.831, total=71, pos=59, neg=12\n",
      "brosnan              bias=0.831, total=59, pos=49, neg=10\n",
      "layers               bias=0.828, total=58, pos=48, neg=10\n",
      "friendship           bias=0.826, total=242, pos=200, neg=42\n",
      "tremendous           bias=0.826, total=121, pos=100, neg=21\n",
      "brilliantly          bias=0.826, total=235, pos=194, neg=41\n",
      "splendid             bias=0.825, total=114, pos=94, neg=20\n",
      "\n",
      "Top negative-associated words:\n",
      "uwe                  bias=0.982, total=57, pos=1, neg=56\n",
      "boll                 bias=0.982, total=56, pos=1, neg=55\n",
      "dreck                bias=0.962, total=79, pos=3, neg=76\n",
      "unwatchable          bias=0.961, total=102, pos=4, neg=98\n",
      "stinker              bias=0.961, total=102, pos=4, neg=98\n",
      "incoherent           bias=0.955, total=132, pos=6, neg=126\n",
      "flimsy               bias=0.944, total=54, pos=3, neg=51\n",
      "yawn                 bias=0.944, total=54, pos=3, neg=51\n",
      "unfunny              bias=0.935, total=230, pos=15, neg=215\n",
      "mst                  bias=0.934, total=137, pos=9, neg=128\n",
      "waste                bias=0.928, total=1300, pos=93, neg=1207\n",
      "ugh                  bias=0.927, total=55, pos=4, neg=51\n",
      "turd                 bias=0.923, total=52, pos=4, neg=48\n",
      "tripe                bias=0.921, total=76, pos=6, neg=70\n",
      "atrocious            bias=0.916, total=191, pos=16, neg=175\n",
      "horrid               bias=0.916, total=107, pos=9, neg=98\n",
      "drivel               bias=0.915, total=118, pos=10, neg=108\n",
      "pointless            bias=0.913, total=459, pos=40, neg=419\n",
      "nope                 bias=0.912, total=57, pos=5, neg=52\n",
      "redeeming            bias=0.911, total=314, pos=28, neg=286\n",
      "blah                 bias=0.910, total=78, pos=7, neg=71\n",
      "wtf                  bias=0.907, total=54, pos=5, neg=49\n",
      "camcorder            bias=0.905, total=63, pos=6, neg=57\n",
      "baldwin              bias=0.904, total=52, pos=5, neg=47\n",
      "lousy                bias=0.904, total=197, pos=19, neg=178\n",
      "laughable            bias=0.902, total=399, pos=39, neg=360\n",
      "unimaginative        bias=0.900, total=60, pos=6, neg=54\n",
      "worst                bias=0.900, total=2260, pos=227, neg=2033\n",
      "wasting              bias=0.898, total=147, pos=15, neg=132\n",
      "remotely             bias=0.897, total=184, pos=19, neg=165\n",
      "excruciatingly       bias=0.895, total=57, pos=6, neg=51\n",
      "awful                bias=0.894, total=1389, pos=147, neg=1242\n",
      "poorly               bias=0.893, total=605, pos=65, neg=540\n",
      "sub-par              bias=0.891, total=64, pos=7, neg=57\n",
      "unoriginal           bias=0.887, total=80, pos=9, neg=71\n",
      "insipid              bias=0.886, total=70, pos=8, neg=62\n",
      "abysmal              bias=0.885, total=96, pos=11, neg=85\n",
      "embarrassingly       bias=0.882, total=51, pos=6, neg=45\n",
      "embarrassment        bias=0.882, total=93, pos=11, neg=82\n",
      "unlikeable           bias=0.879, total=58, pos=7, neg=51\n",
      "insult               bias=0.879, total=207, pos=25, neg=182\n",
      "non-existent         bias=0.879, total=124, pos=15, neg=109\n",
      "boredom              bias=0.878, total=139, pos=17, neg=122\n",
      "lame                 bias=0.877, total=633, pos=78, neg=555\n",
      "sucks                bias=0.876, total=251, pos=31, neg=220\n",
      "miserably            bias=0.876, total=121, pos=15, neg=106\n",
      "uninspired           bias=0.876, total=121, pos=15, neg=106\n",
      "stupidity            bias=0.873, total=150, pos=19, neg=131\n",
      "inane                bias=0.872, total=94, pos=12, neg=82\n",
      "unintentional        bias=0.871, total=101, pos=13, neg=88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify words coorelating with sentiment bias\n",
    "\n",
    "min_count = 50  # min #reviews containing the word to be considered\n",
    "\n",
    "# vocab = nion of pos/ negativ\n",
    "vocab = set(c_pos_word.keys()) | set(c_neg_word.keys())\n",
    "\n",
    "pos_rank = []  # (word, bias_pos, total, count_pos, count_neg)\n",
    "neg_rank = []  # (word, bias_neg, total, count_pos, count_neg)\n",
    "\n",
    "for word in vocab: #loop over all words and count occurances\n",
    "    count_pos = c_pos_word[word]\n",
    "    count_neg = c_neg_word[word]\n",
    "    total = count_pos + count_neg\n",
    "    if total < min_count: # skip if word is too rare\n",
    "        continue\n",
    "\n",
    "    # bias metric\n",
    "    bias_pos = count_pos / total  # in [0,1]: ratio of how often word appears in positive sentiment 1.0:only positiv; 0,0 only negative\n",
    "\n",
    "    if bias_pos > 0.5:\n",
    "        # more positive than negative\n",
    "        pos_rank.append((word, bias_pos, total, count_pos, count_neg))\n",
    "    elif bias_pos < 0.5:\n",
    "        # more negative than positive\n",
    "        bias_neg = 1.0 - bias_pos\n",
    "        neg_rank.append((word, bias_neg, total, count_pos, count_neg))\n",
    "\n",
    "# Sort:\n",
    "# - first by bias strength (more extreme first)\n",
    "# - tie-break by total support (more occurrences first)\n",
    "pos_rank.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "neg_rank.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "\n",
    "print(\"Top positive-associated words:\")\n",
    "for word, bias, total, count_pos, count_neg in pos_rank[:50]:\n",
    "    print(f\"{word:20s} bias={bias:.3f}, total={total}, pos={count_pos}, neg={count_neg}\")\n",
    "\n",
    "print(\"\\nTop negative-associated words:\")\n",
    "for word, bias, total, count_pos, count_neg in neg_rank[:50]:\n",
    "    print(f\"{word:20s} bias={bias:.3f}, total={total}, pos={count_pos}, neg={count_neg}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d5a56ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spielberg  total=  78 pos=  48 neg=  30 bias_pos=0.615\n",
      "tarantino  total=  56 pos=  21 neg=  35 bias_pos=0.375\n",
      "scorsese   total=  31 pos=  16 neg=  15 bias_pos=0.516\n",
      "norris     total=  20 pos=   7 neg=  13 bias_pos=0.350\n",
      "seagal     total=  49 pos=   3 neg=  46 bias_pos=0.061\n"
     ]
    }
   ],
   "source": [
    "# check for words in list\n",
    "for word in [\"spielberg\", \"tarantino\", \"scorsese\", \"norris\", \"seagal\"]:\n",
    "    count_pos = c_pos_word[word]\n",
    "    count_neg = c_neg_word[word]\n",
    "    total = count_pos + count_neg\n",
    "    if total > 0:\n",
    "        bias_pos = count_pos / total\n",
    "        print(f\"{word:10s} total={total:4d} pos={count_pos:4d} neg={count_neg:4d} bias_pos={bias_pos:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb124028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive shortcut-like candidates:\n",
      "edie                 bias_pos=1.000 total=  39 pos=  39 neg=   0\n",
      "paulie               bias_pos=0.974 total=  38 pos=  37 neg=   1\n",
      "first-rate           bias_pos=0.943 total=  53 pos=  50 neg=   3\n",
      "vulnerability        bias_pos=0.941 total=  34 pos=  32 neg=   2\n",
      "harriet              bias_pos=0.939 total=  33 pos=  31 neg=   2\n",
      "carell               bias_pos=0.938 total=  32 pos=  30 neg=   2\n",
      "flawless             bias_pos=0.934 total= 122 pos= 114 neg=   8\n",
      "enchanting           bias_pos=0.933 total=  45 pos=  42 neg=   3\n",
      "chamberlain          bias_pos=0.933 total=  30 pos=  28 neg=   2\n",
      "raines               bias_pos=0.927 total=  41 pos=  38 neg=   3\n",
      "influential          bias_pos=0.925 total=  40 pos=  37 neg=   3\n",
      "matthau              bias_pos=0.923 total=  65 pos=  60 neg=   5\n",
      "kinnear              bias_pos=0.919 total=  37 pos=  34 neg=   3\n",
      "felix                bias_pos=0.918 total=  49 pos=  45 neg=   4\n",
      "mclaglen             bias_pos=0.911 total=  45 pos=  41 neg=   4\n",
      "kelly's              bias_pos=0.909 total=  33 pos=  30 neg=   3\n",
      "layered              bias_pos=0.909 total=  33 pos=  30 neg=   3\n",
      "devotion             bias_pos=0.907 total=  43 pos=  39 neg=   4\n",
      "vance                bias_pos=0.906 total=  32 pos=  29 neg=   3\n",
      "ramones              bias_pos=0.906 total=  32 pos=  29 neg=   3\n",
      "sirk                 bias_pos=0.903 total=  31 pos=  28 neg=   3\n",
      "winchester           bias_pos=0.903 total=  31 pos=  28 neg=   3\n",
      "transcends           bias_pos=0.903 total=  31 pos=  28 neg=   3\n",
      "perfection           bias_pos=0.903 total= 134 pos= 121 neg=  13\n",
      "massey               bias_pos=0.900 total=  30 pos=  27 neg=   3\n",
      "enthralling          bias_pos=0.897 total=  39 pos=  35 neg=   4\n",
      "fairbanks            bias_pos=0.897 total=  39 pos=  35 neg=   4\n",
      "novak                bias_pos=0.895 total=  38 pos=  34 neg=   4\n",
      "tenant               bias_pos=0.892 total=  37 pos=  33 neg=   4\n",
      "fritz                bias_pos=0.892 total=  37 pos=  33 neg=   4\n",
      "truman               bias_pos=0.889 total=  45 pos=  40 neg=   5\n",
      "captures             bias_pos=0.887 total= 203 pos= 180 neg=  23\n",
      "mccoy                bias_pos=0.886 total=  44 pos=  39 neg=   5\n",
      "malone               bias_pos=0.886 total=  44 pos=  39 neg=   5\n",
      "greene               bias_pos=0.886 total=  35 pos=  31 neg=   4\n",
      "northam              bias_pos=0.886 total=  35 pos=  31 neg=   4\n",
      "explores             bias_pos=0.882 total=  68 pos=  60 neg=   8\n",
      "hawke                bias_pos=0.882 total=  51 pos=  45 neg=   6\n",
      "mildred              bias_pos=0.882 total=  34 pos=  30 neg=   4\n",
      "corbin               bias_pos=0.882 total=  34 pos=  30 neg=   4\n",
      "masterful            bias_pos=0.881 total=  84 pos=  74 neg=  10\n",
      "stewart's            bias_pos=0.881 total=  42 pos=  37 neg=   5\n",
      "polanski             bias_pos=0.879 total=  33 pos=  29 neg=   4\n",
      "precise              bias_pos=0.875 total=  48 pos=  42 neg=   6\n",
      "georges              bias_pos=0.875 total=  40 pos=  35 neg=   5\n",
      "refreshing           bias_pos=0.873 total= 197 pos= 172 neg=  25\n",
      "kline                bias_pos=0.872 total=  47 pos=  41 neg=   6\n",
      "breathtaking         bias_pos=0.871 total= 163 pos= 142 neg=  21\n",
      "must-see             bias_pos=0.871 total= 124 pos= 108 neg=  16\n",
      "ealing               bias_pos=0.871 total=  31 pos=  27 neg=   4\n",
      "\n",
      "Negative shortcut-like candidates:\n",
      "boll                 bias_neg=0.982 total=  56 pos=   1 neg=  55\n",
      "steaming             bias_neg=0.974 total=  38 pos=   1 neg=  37\n",
      "awfulness            bias_neg=0.973 total=  37 pos=   1 neg=  36\n",
      "interminable         bias_neg=0.968 total=  31 pos=   1 neg=  30\n",
      "dreck                bias_neg=0.962 total=  79 pos=   3 neg=  76\n",
      "incoherent           bias_neg=0.955 total= 132 pos=   6 neg= 126\n",
      "semblance            bias_neg=0.952 total=  42 pos=   2 neg=  40\n",
      "flimsy               bias_neg=0.944 total=  54 pos=   3 neg=  51\n",
      "yawn                 bias_neg=0.944 total=  54 pos=   3 neg=  51\n",
      "revolting            bias_neg=0.939 total=  33 pos=   2 neg=  31\n",
      "seagal               bias_neg=0.939 total=  49 pos=   3 neg=  46\n",
      "god-awful            bias_neg=0.936 total=  47 pos=   3 neg=  44\n",
      "turgid               bias_neg=0.935 total=  31 pos=   2 neg=  29\n",
      "unfunny              bias_neg=0.935 total= 230 pos=  15 neg= 215\n",
      "vacuous              bias_neg=0.933 total=  30 pos=   2 neg=  28\n",
      "paycheck             bias_neg=0.929 total=  42 pos=   3 neg=  39\n",
      "turd                 bias_neg=0.923 total=  52 pos=   4 neg=  48\n",
      "tripe                bias_neg=0.921 total=  76 pos=   6 neg=  70\n",
      "tedium               bias_neg=0.917 total=  36 pos=   3 neg=  33\n",
      "atrocious            bias_neg=0.916 total= 191 pos=  16 neg= 175\n",
      "horrid               bias_neg=0.916 total= 107 pos=   9 neg=  98\n",
      "drivel               bias_neg=0.915 total= 118 pos=  10 neg= 108\n",
      "fast-forward         bias_neg=0.914 total=  35 pos=   3 neg=  32\n",
      "pointless            bias_neg=0.913 total= 459 pos=  40 neg= 419\n",
      "nope                 bias_neg=0.912 total=  57 pos=   5 neg=  52\n",
      "redeeming            bias_neg=0.911 total= 314 pos=  28 neg= 286\n",
      "blah                 bias_neg=0.910 total=  78 pos=   7 neg=  71\n",
      "existent             bias_neg=0.909 total=  33 pos=   3 neg=  30\n",
      "camcorder            bias_neg=0.905 total=  63 pos=   6 neg=  57\n",
      "vapid                bias_neg=0.905 total=  42 pos=   4 neg=  38\n",
      "baldwin              bias_neg=0.904 total=  52 pos=   5 neg=  47\n",
      "lousy                bias_neg=0.904 total= 197 pos=  19 neg= 178\n",
      "monstrosity          bias_neg=0.903 total=  31 pos=   3 neg=  28\n",
      "mcdowell             bias_neg=0.903 total=  31 pos=   3 neg=  28\n",
      "abomination          bias_neg=0.902 total=  41 pos=   4 neg=  37\n",
      "laughable            bias_neg=0.902 total= 399 pos=  39 neg= 360\n",
      "unimaginative        bias_neg=0.900 total=  60 pos=   6 neg=  54\n",
      "stunk                bias_neg=0.900 total=  30 pos=   3 neg=  27\n",
      "mutated              bias_neg=0.900 total=  30 pos=   3 neg=  27\n",
      "midget               bias_neg=0.900 total=  30 pos=   3 neg=  27\n",
      "fiasco               bias_neg=0.895 total=  38 pos=   4 neg=  34\n",
      "stereotyped          bias_neg=0.894 total=  47 pos=   5 neg=  42\n",
      "sub-par              bias_neg=0.891 total=  64 pos=   7 neg=  57\n",
      "damme                bias_neg=0.889 total=  45 pos=   5 neg=  40\n",
      "unoriginal           bias_neg=0.887 total=  80 pos=   9 neg=  71\n",
      "insipid              bias_neg=0.886 total=  70 pos=   8 neg=  62\n",
      "abysmal              bias_neg=0.885 total=  96 pos=  11 neg=  85\n",
      "embarrassment        bias_neg=0.882 total=  93 pos=  11 neg=  82\n",
      "monotonous           bias_neg=0.881 total=  42 pos=   5 neg=  37\n",
      "unnatural            bias_neg=0.881 total=  42 pos=   5 neg=  37\n"
     ]
    }
   ],
   "source": [
    "min_count = 30          # a bit lower to catch rarer names\n",
    "bias_threshold = 0.80   # strong skew\n",
    "\n",
    "sentiment_like = {\n",
    "    \"excellent\",\"awful\",\"terrible\",\"great\",\"bad\",\"superb\",\"outstanding\",\"perfect\",\n",
    "    \"boring\",\"waste\",\"wasted\",\"wasting\",\"worst\",\"gem\",\"marvelous\",\"pathetic\",\n",
    "    \"unwatchable\",\"unforgettable\",\"heartwarming\",\"heartbreaking\",\"dreadful\",\n",
    "    \"fabulous\",\"awesome\",\"amazing\",\"sucks\",\"rubbish\",\"stinker\",\"lifeless\",\n",
    "    # TODO: Extend\n",
    "}\n",
    "\n",
    "def is_suspect(word):\n",
    "    # crude heuristic: skip common sentiment suffixes/adverbs/adjectives\n",
    "    if word in sentiment_like:\n",
    "        return False\n",
    "    if word.endswith((\"ly\", \"est\")):\n",
    "        return False\n",
    "    if len(word) <= 3:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "vocab = set(c_pos_word.keys()) | set(c_neg_word.keys())\n",
    "\n",
    "pos_suspects = []\n",
    "neg_suspects = []\n",
    "\n",
    "# Same bias calculation as above\n",
    "for word in vocab:\n",
    "    count_pos = c_pos_word[word]\n",
    "    count_neg = c_neg_word[word]\n",
    "    total = count_pos + count_neg\n",
    "    if total < min_count:\n",
    "        continue\n",
    "\n",
    "    bias_pos = count_pos / total\n",
    "\n",
    "    if bias_pos >= bias_threshold and is_suspect(word): #filter\n",
    "        pos_suspects.append((word, bias_pos, total, count_pos, count_neg))\n",
    "    elif (1 - bias_pos) >= bias_threshold and is_suspect(word): #filter for negative\n",
    "        neg_suspects.append((word, 1 - bias_pos, total, count_pos, count_neg))\n",
    "\n",
    "pos_suspects.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "neg_suspects.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
    "\n",
    "print(\"Positive shortcut-like candidates:\")\n",
    "for word, bias, total, count_pos, count_neg in pos_suspects[:50]:\n",
    "    print(f\"{word:20s} bias_pos={bias:.3f} total={total:4d} pos={count_pos:4d} neg={count_neg:4d}\")\n",
    "\n",
    "print(\"\\nNegative shortcut-like candidates:\")\n",
    "for word, bias, total, count_pos, count_neg in neg_suspects[:50]:\n",
    "    print(f\"{word:20s} bias_neg={bias:.3f} total={total:4d} pos={count_pos:4d} neg={count_neg:4d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97c3305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase/Pattern: 'spielberg' (regex=False)\n",
      "Number of examples: 101\n",
      "Accuracy: 0.9901\n",
      "Gold label distribution (0=neg, 1=pos): Counter({1: 60, 0: 41})\n",
      "Pred label distribution (0=neg, 1=pos): Counter({1: 61, 0: 40})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'phrase': 'spielberg',\n",
       " 'regex_used': False,\n",
       " 'num_examples': 101,\n",
       " 'accuracy': 0.9900990099009901,\n",
       " 'gold_label_distribution': {0: 41, 1: 60},\n",
       " 'pred_label_distribution': {0: 40, 1: 61}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_phrase_subset(model, tokenizer, dataset[\"train\"],\n",
    "                       phrase=\"spielberg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad1d91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 68/68 [00:00<00:00, 407.37 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase/Pattern: 'matthau' (regex=False)\n",
      "Number of examples: 68\n",
      "Accuracy: 0.9853\n",
      "Gold label distribution (0=neg, 1=pos): Counter({1: 63, 0: 5})\n",
      "Pred label distribution (0=neg, 1=pos): Counter({1: 62, 0: 6})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'phrase': 'matthau',\n",
       " 'regex_used': False,\n",
       " 'num_examples': 68,\n",
       " 'accuracy': 0.9852941176470589,\n",
       " 'gold_label_distribution': {0: 5, 1: 63},\n",
       " 'pred_label_distribution': {0: 6, 1: 62}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "evaluate_phrase_subset(model, tokenizer, dataset[\"train\"],\n",
    "                       phrase=\"matthau\")\n",
    "# TODO: Idea:generate samples with lobsided words (identified by expert?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spielberg → seagal: 1/53 predictions flipped (0.019)\n",
      "seagal → spielberg: 0/99 predictions flipped (0.000)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Rewrite flip test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "936b21f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Delete test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bdee6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add amplification metric\n",
    "\n",
    "\n",
    "    # gold_pos = s[\"gold_pos_rate\"]\n",
    "    # pred_pos = s[\"pred_pos_rate\"]\n",
    "    # amp = pred_pos - gold_pos  # >0: model more positive than data; <0: more negative\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
