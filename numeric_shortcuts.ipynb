{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0fba189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "########################################\n",
    "# 1. Load *your* fine-tuned DistilBERT\n",
    "########################################\n",
    "\n",
    "model_path = \"./distillbert-base-finetuned\"\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\"lvwerra/distilbert-imdb\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "########################################\n",
    "# 2. Prediction helper\n",
    "########################################\n",
    "\n",
    "def predict(text):\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    enc = {k: v.to(device) for k, v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "    probs = softmax(logits, dim=-1).cpu().numpy()[0]\n",
    "    pred = int(np.argmax(probs))\n",
    "    return pred, probs\n",
    "\n",
    "########################################\n",
    "# 3. Grad-L2 saliency (DistilBERT)\n",
    "########################################\n",
    "\n",
    "def grad_l2_saliency(text):\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=512)\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attention_mask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    inputs_embeds = model.distilbert.embeddings(input_ids)\n",
    "    inputs_embeds.retain_grad()\n",
    "\n",
    "    outputs = model(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    target_logit = logits[0, logits.argmax(dim=-1)]\n",
    "\n",
    "    target_logit.backward()\n",
    "\n",
    "    grad = inputs_embeds.grad[0]\n",
    "    saliency = torch.norm(grad, dim=-1)\n",
    "\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    return tokens, saliency.detach().cpu().numpy()\n",
    "\n",
    "########################################\n",
    "# 4. Rating extraction\n",
    "########################################\n",
    "\n",
    "rating_regex = re.compile(r\"(\\d+)\\s*(/|out of)\\s*10\")\n",
    "\n",
    "def extract_rating_reviews(texts):\n",
    "    return [t for t in texts if rating_regex.search(t)]\n",
    "\n",
    "########################################\n",
    "# 5. Numeric shortcut detection\n",
    "########################################\n",
    "\n",
    "def is_rating_token(tok):\n",
    "    core = tok.replace(\"##\", \"\")\n",
    "    return core.isdigit() or tok in [\"/\", \"out\", \"of\"]\n",
    "\n",
    "def top_k_saliency(tokens, saliency, k=5):\n",
    "    idxs = np.argsort(-saliency)[:k]\n",
    "    return [(tokens[i], float(saliency[i])) for i in idxs]\n",
    "\n",
    "########################################\n",
    "# 6. Masking\n",
    "########################################\n",
    "\n",
    "def mask_rating(text):\n",
    "    mask = tokenizer.mask_token\n",
    "    return rating_regex.sub(f\"{mask} {mask}\", text)\n",
    "\n",
    "def masking_effect(text):\n",
    "    pred_o, probs_o = predict(text)\n",
    "    masked = mask_rating(text)\n",
    "    pred_m, probs_m = predict(masked)\n",
    "    delta = probs_o - probs_m\n",
    "    return pred_o, probs_o, pred_m, probs_m, delta\n",
    "\n",
    "########################################\n",
    "# 7. Injection\n",
    "########################################\n",
    "\n",
    "def injection_effect(text, rating=\"3/10\"):\n",
    "    pred_b, probs_b = predict(text)\n",
    "    inj = text + \" \" + rating\n",
    "    pred_i, probs_i = predict(inj)\n",
    "    diff = probs_i - probs_b\n",
    "    return pred_b, probs_b, pred_i, probs_i, diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9f860633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/10 → ['3', '/', '10']\n",
      "8/10 → ['8', '/', '10']\n",
      "9/10 → ['9', '/', '10']\n",
      "10/10 → ['10', '/', '10']\n",
      "4 out of 10 → ['4', 'out', 'of', '10']\n",
      "7 out of 10 → ['7', 'out', 'of', '10']\n"
     ]
    }
   ],
   "source": [
    "ratings = [\"3/10\", \"8/10\", \"9/10\", \"10/10\", \"4 out of 10\", \"7 out of 10\"]\n",
    "\n",
    "for r in ratings:\n",
    "    print(r, \"→\", tokenizer.tokenize(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "251cb015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rating reviews ===\n",
      "- The movie was boring and too long. 3/10\n",
      "- I really loved this film, the acting was great. 9/10\n",
      "\n",
      "=== Saliency top-5 ===\n",
      "\n",
      "TEXT: The movie was boring and too long. 3/10\n",
      "TOP-5: [('[CLS]', 0.08184252679347992), ('boring', 0.06775245070457458), ('[SEP]', 0.03804617002606392), ('.', 0.03294209763407707), ('movie', 0.03236350789666176), ('too', 0.02763078175485134), ('and', 0.027482308447360992), ('was', 0.025327077135443687), ('/', 0.025030042976140976), ('10', 0.021791422739624977)]\n",
      "\n",
      "TEXT: I really loved this film, the acting was great. 9/10\n",
      "TOP-5: [('[CLS]', 0.06422299146652222), ('loved', 0.05984452739357948), ('great', 0.040279317647218704), ('acting', 0.029215823858976364), ('film', 0.027716677635908127), ('really', 0.026736430823802948), ('[SEP]', 0.026489077135920525), ('this', 0.026347951963543892), (',', 0.025353582575917244), ('i', 0.02284826524555683)]\n",
      "\n",
      "=== Masking experiment ===\n",
      "\n",
      "Original: The movie was boring and too long. 3/10\n",
      "Pred original: 0 [0.99658066 0.00341933]\n",
      "Pred masked:   0 [0.93435925 0.06564078]\n",
      "Delta (orig - masked): [ 0.06222141 -0.06222145]\n",
      "\n",
      "Original: I really loved this film, the acting was great. 9/10\n",
      "Pred original: 1 [0.00378348 0.9962165 ]\n",
      "Pred masked:   1 [0.01359672 0.9864032 ]\n",
      "Delta (orig - masked): [-0.00981323  0.00981325]\n",
      "\n",
      "=== Injection experiment (3/10 added) ===\n",
      "\n",
      "Base: The movie was boring and too long. 3/10\n",
      "Base pred: 0 [0.99658066 0.00341933]\n",
      "Injected pred: 0 [0.99647176 0.0035283 ]\n",
      "Delta: [-0.0001089   0.00010897]\n",
      "\n",
      "Base: I really loved this film, the acting was great. 9/10\n",
      "Base pred: 1 [0.00378348 0.9962165 ]\n",
      "Injected pred: 1 [0.00381436 0.9961856 ]\n",
      "Delta: [ 3.0874508e-05 -3.0875206e-05]\n",
      "\n",
      "Base: Not good, not terrible, just average.\n",
      "Base pred: 0 [0.9638412  0.03615877]\n",
      "Injected pred: 0 [0.89856017 0.10143983]\n",
      "Delta: [-0.06528103  0.06528106]\n",
      "\n",
      "Base: Terrible script, but the visuals were okay.\n",
      "Base pred: 0 [0.98870414 0.01129583]\n",
      "Injected pred: 0 [0.9875392  0.01246081]\n",
      "Delta: [-0.00116497  0.00116499]\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "# 8. EXAMPLE USAGE — RUN ANALYSIS\n",
    "########################################\n",
    "\n",
    "\n",
    "\n",
    "# Example texts — replace with IMDB test set\n",
    "sample_texts = [\n",
    "    \"The movie was boring and too long. 3/10\",\n",
    "    \"I really loved this film, the acting was great. 9/10\",\n",
    "    \"Not good, not terrible, just average.\",\n",
    "    \"Terrible script, but the visuals were okay.\",\n",
    "]\n",
    "\n",
    "########################################\n",
    "# A) Extract rating reviews\n",
    "########################################\n",
    "rating_reviews = extract_rating_reviews(sample_texts)\n",
    "print(\"\\n=== Rating reviews ===\")\n",
    "for r in rating_reviews:\n",
    "    print(\"-\", r)\n",
    "\n",
    "########################################\n",
    "# B) Saliency inspection\n",
    "########################################\n",
    "print(\"\\n=== Saliency top-5 ===\")\n",
    "for text in rating_reviews:\n",
    "    tokens, sal = grad_l2_saliency(text)\n",
    "    top = top_k_saliency(tokens, sal,k=10)\n",
    "    print(\"\\nTEXT:\", text)\n",
    "    print(\"TOP-5:\", top)\n",
    "\n",
    "########################################\n",
    "# C) Masking experiment\n",
    "########################################\n",
    "print(\"\\n=== Masking experiment ===\")\n",
    "for text in rating_reviews:\n",
    "    print(\"\\nOriginal:\", text)\n",
    "    pred_o, p_o, pred_m, p_m, delta = masking_effect(text)\n",
    "    print(\"Pred original:\", pred_o, p_o)\n",
    "    print(\"Pred masked:  \", pred_m, p_m)\n",
    "    print(\"Delta (orig - masked):\", delta)\n",
    "\n",
    "########################################\n",
    "# D) Injection experiment\n",
    "########################################\n",
    "print(\"\\n=== Injection experiment (3/10 added) ===\")\n",
    "for text in sample_texts:\n",
    "    print(\"\\nBase:\", text)\n",
    "    pred_b, pb, pred_i, pi, diff = injection_effect(text, rating=\"3/10\")\n",
    "    print(\"Base pred:\", pred_b, pb)\n",
    "    print(\"Injected pred:\", pred_i, pi)\n",
    "    print(\"Delta:\", diff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b82ba0b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================\n",
      "FINAL VERDICT: NO SHORTCUT\n",
      "==========================\n",
      "\n",
      "TEXT: The movie was nice and short. 7/10\n",
      "  TOP-5: [('[CLS]', 0.2948637008666992), ('nice', 0.27593621611595154), ('short', 0.23620843887329102), ('movie', 0.1456511914730072), ('[SEP]', 0.13727544248104095)]\n",
      "  numeric in top5: False\n",
      "  mask_strength: 0.18076348304748535\n",
      "  inj_strength: 0.001068711280822754\n",
      "\n",
      "TEXT: I really loved this film, the acting was great. 9/10\n",
      "  TOP-5: [('[CLS]', 0.06422295421361923), ('loved', 0.0598444901406765), ('great', 0.040279362350702286), ('acting', 0.029215846210718155), ('film', 0.027716660872101784)]\n",
      "  numeric in top5: False\n",
      "  mask_strength: 0.009813249111175537\n",
      "  inj_strength: 3.0875205993652344e-05\n",
      "\n",
      "TEXT: Terrible script, terrible pacing.\n",
      "  TOP-5: [('[CLS]', 0.20993156731128693), ('terrible', 0.16055268049240112), ('terrible', 0.12942366302013397), ('pacing', 0.1133435070514679), ('[SEP]', 0.10292033106088638)]\n",
      "  numeric in top5: False\n",
      "  mask_strength: 0.0\n",
      "  inj_strength: 0.0002428889274597168\n",
      "\n",
      "TEXT: I loved every minute of this film!\n",
      "  TOP-5: [('[CLS]', 0.11458208411931992), ('loved', 0.06494313478469849), ('[SEP]', 0.033417366445064545), ('!', 0.03256421536207199), ('every', 0.02980986423790455)]\n",
      "  numeric in top5: False\n",
      "  mask_strength: 0.0\n",
      "  inj_strength: 0.00038177287206053734\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import re\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "###############################################\n",
    "# 0. Load your model — BERT or DistilBERT\n",
    "###############################################\n",
    "\n",
    "model_path = \"./distillbert-base-finetuned\"\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_path)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "model.eval() \n",
    "\n",
    "\n",
    "###############################################\n",
    "# 1. Find embeddings layer (supports BERT & DistilBERT)\n",
    "###############################################\n",
    "\n",
    "def get_embeddings_layer(model):\n",
    "    if hasattr(model, \"bert\"):\n",
    "        return model.bert.embeddings\n",
    "    if hasattr(model, \"distilbert\"):\n",
    "        return model.distilbert.embeddings\n",
    "    if hasattr(model, \"roberta\"):\n",
    "        return model.roberta.embeddings\n",
    "    raise ValueError(\"Unsupported model type — add embedding lookup rule.\")\n",
    "\n",
    "###############################################\n",
    "# 2. Prediction helper\n",
    "###############################################\n",
    "\n",
    "def predict(text):\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
    "    enc = {k: v.to(device) for k,v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "    probs = softmax(logits, dim=-1)[0].cpu().numpy()\n",
    "    return int(np.argmax(probs)), probs\n",
    "\n",
    "###############################################\n",
    "# 3. Grad-L2 saliency\n",
    "###############################################\n",
    "\n",
    "def grad_l2_saliency(text):\n",
    "    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=256)\n",
    "    input_ids = enc[\"input_ids\"].to(device)\n",
    "    attention_mask = enc[\"attention_mask\"].to(device)\n",
    "\n",
    "    model.zero_grad()\n",
    "\n",
    "    # get embeddings with gradient\n",
    "    embeddings_layer = get_embeddings_layer(model)\n",
    "    inputs_embeds = embeddings_layer(input_ids)\n",
    "    inputs_embeds.retain_grad()\n",
    "\n",
    "    outputs = model(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
    "    logits = outputs.logits\n",
    "    target = logits[0, logits.argmax(-1)]\n",
    "    target.backward()\n",
    "\n",
    "    grad = inputs_embeds.grad[0]          # (seq, hidden)\n",
    "    sal = torch.norm(grad, dim=-1).cpu().numpy()\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "    return tokens, sal\n",
    "\n",
    "###############################################\n",
    "# 4. Saliency Top-k\n",
    "###############################################\n",
    "\n",
    "def top_k_saliency(tokens, sal, k=5):\n",
    "    idx = np.argsort(-sal)[:k]\n",
    "    return [(tokens[i], float(sal[i])) for i in idx]\n",
    "\n",
    "###############################################\n",
    "# 5. Shortcut tests: masking and injecting\n",
    "###############################################\n",
    "\n",
    "rating_pattern = re.compile(r\"(\\d+)\\s*(/|out of)\\s*10\")\n",
    "\n",
    "def mask_rating(text):\n",
    "    return rating_pattern.sub(\"[MASK] [MASK]\", text)\n",
    "\n",
    "def masking_test(text):\n",
    "    pred_o, p_o = predict(text)\n",
    "    pred_m, p_m = predict(mask_rating(text))\n",
    "    delta = p_o - p_m\n",
    "    return delta, pred_o, pred_m, p_o, p_m\n",
    "\n",
    "def inject(text, rating=\"3/10\"):\n",
    "    return text.strip() + f\" {rating}\"\n",
    "\n",
    "def injection_test(text, rating=\"3/10\"):\n",
    "    pred_o, p_o = predict(text)\n",
    "    pred_i, p_i = predict(inject(text, rating))\n",
    "    delta = p_i - p_o\n",
    "    return delta, pred_o, pred_i, p_o, p_i\n",
    "\n",
    "###############################################\n",
    "# 6. Shortcut detection logic\n",
    "###############################################\n",
    "\n",
    "def detect_shortcut(example_texts):\n",
    "    results = []\n",
    "\n",
    "    for text in example_texts:\n",
    "\n",
    "        # A. Saliency check\n",
    "        tokens, sal = grad_l2_saliency(text)\n",
    "        top5 = top_k_saliency(tokens, sal)\n",
    "        numeric_in_top5 = any(re.fullmatch(r\"\\d+|/|##\\d+\", tok) for tok, _ in top5)\n",
    "\n",
    "        # B. Masking check\n",
    "        delta_mask, pred_o, pred_m, p_o, p_m = masking_test(text)\n",
    "        mask_strength = np.abs(delta_mask).max()\n",
    "\n",
    "        # C. Injection check (into same text)\n",
    "        delta_inj, _, _, _, _ = injection_test(text)\n",
    "        inj_strength = np.abs(delta_inj).max()\n",
    "\n",
    "        results.append({\n",
    "            \"text\": text,\n",
    "            \"top5\": top5,\n",
    "            \"numeric_in_top5\": numeric_in_top5,\n",
    "            \"mask_strength\": float(mask_strength),\n",
    "            \"inj_strength\": float(inj_strength),\n",
    "        })\n",
    "\n",
    "    #############################################################\n",
    "    # Aggregate verdict\n",
    "    #############################################################\n",
    "\n",
    "    num_top5_count = sum(r[\"numeric_in_top5\"] for r in results)\n",
    "    avg_mask = np.mean([r[\"mask_strength\"] for r in results])\n",
    "    avg_inj = np.mean([r[\"inj_strength\"] for r in results])\n",
    "\n",
    "    shortcut = (\n",
    "        num_top5_count >= len(results) * 0.5 and\n",
    "        (avg_mask > 0.10 or avg_inj > 0.10)\n",
    "    )\n",
    "\n",
    "    verdict = \"SHORTCUT DETECTED\" if shortcut else \"NO SHORTCUT\"\n",
    "    return verdict, results\n",
    "\n",
    "###############################################\n",
    "# 7. Example usage\n",
    "###############################################\n",
    "\n",
    "test_texts = [\n",
    "    \"The movie was nice and short. 7/10\",\n",
    "    \"I really loved this film, the acting was great. 9/10\",\n",
    "    \"Terrible script, terrible pacing.\",\n",
    "    \"I loved every minute of this film!\",\n",
    "]\n",
    "\n",
    "verdict, details = detect_shortcut(test_texts)\n",
    "\n",
    "print(\"\\n==========================\")\n",
    "print(\"FINAL VERDICT:\", verdict)\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "for r in details:\n",
    "    print(\"TEXT:\", r[\"text\"])\n",
    "    print(\"  TOP-5:\", r[\"top5\"])\n",
    "    print(\"  numeric in top5:\", r[\"numeric_in_top5\"])\n",
    "    print(\"  mask_strength:\", r[\"mask_strength\"])\n",
    "    print(\"  inj_strength:\", r[\"inj_strength\"])\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "082cc1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leosteiner/Desktop/BT/.venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1731: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_path = \"./tinybert-imdb-final\"\n",
    "\n",
    "# IMPORTANT: use Auto* and remove any DistilBert/Bert-specific imports\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "def predict(text):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "    return int(logits.argmax(-1))\n",
    "\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "\n",
    "subset = dataset[\"test\"].select(range(4000))\n",
    "\n",
    "for sample in subset:\n",
    "    preds.append(predict(sample[\"text\"]))\n",
    "    labels.append(sample[\"label\"])\n",
    "\n",
    "acc = accuracy_score(labels, preds)\n",
    "f1 = f1_score(labels, preds)\n",
    "\n",
    "print(\"Accuracy:\", acc)\n",
    "print(\"F1:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b1df17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rating patterns: 4376\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import re\n",
    "\n",
    "dataset = load_dataset(\"imdb\")\n",
    "pattern = re.compile(r\"\\b\\d+\\s*(/|out of)\\s*10\\b\")\n",
    "\n",
    "count = sum(1 for x in dataset[\"train\"][\"text\"] if pattern.search(x))\n",
    "count += sum(1 for x in dataset[\"test\"][\"text\"] if pattern.search(x))\n",
    "\n",
    "print(\"Number of rating patterns:\", count)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
